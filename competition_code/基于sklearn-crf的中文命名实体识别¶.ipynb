{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "metallic-mortgage",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import metrics\n",
    "import joblib\n",
    "import yaml\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "orange-lloyd",
   "metadata": {},
   "source": [
    "## 加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "biological-catholic",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path):\n",
    "    data = list()\n",
    "    data_sent_with_label = list()\n",
    "    with open(data_path, mode='r', encoding=\"utf-8\") as f:\n",
    "        for line in tqdm(f):\n",
    "            if line.strip() == \"\":\n",
    "                data.append(data_sent_with_label.copy())\n",
    "                data_sent_with_label.clear()\n",
    "            else:\n",
    "                row_data=line.strip().split(\" \")\n",
    "                if len(row_data)==1:\n",
    "                    data_sent_with_label.append((' ',row_data[0]))\n",
    "                else:\n",
    "                    data_sent_with_label.append(tuple(line.strip().split(\" \")))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "legitimate-deadline",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'  O'.split()结果为： ['O']\n",
      "'  O'.strip()结果为： O\n"
     ]
    }
   ],
   "source": [
    "print(\"'  O'.split()结果为：\",'  O'.split())\n",
    "print(\"'  O'.strip()结果为：\",'  O'.strip())\n",
    "# print(\"' \\n'.strip()结果为：\",' \\n'.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "nuclear-guidance",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2288790it [00:02, 894592.00it/s] \n"
     ]
    }
   ],
   "source": [
    "train=load_data('data/train_data/train.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "hairy-polyester",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "exempt-qualification",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32000 8000\n"
     ]
    }
   ],
   "source": [
    "train,valid=train_test_split(train,test_size=0.2,shuffle=True,random_state=42)\n",
    "print(len(train),len(valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "random-mercy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.isspace()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "compatible-search",
   "metadata": {},
   "source": [
    "## 构造ngram特征"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "actual-panel",
   "metadata": {},
   "outputs": [],
   "source": [
    "def word2features(sent, i):\n",
    "    word = sent[i][0]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word': word,\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'word.isspace()': word.isspace(),\n",
    "        'word.isalpha()': word.isalpha(),\n",
    "        \n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        words = word1 + word\n",
    "        features.update({\n",
    "            '-1:word': word1,\n",
    "            '-1:words': words,\n",
    "            '-1:word.isdigit()': word1.isdigit(),\n",
    "            '-1:word.isspace()': word1.isalpha(),\n",
    "\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "#     if i > 1:\n",
    "#         word2 = sent[i-2][0]\n",
    "#         word1 = sent[i-1][0]\n",
    "#         words = word1 + word2 + word\n",
    "#         features.update({\n",
    "#             '-2:word': word2,\n",
    "#             '-2:words': words,\n",
    "#             '-2:word.isdigit()': word2.isdigit(),\n",
    "#             '-2:word.isspace()': word2.isalpha(),\n",
    "\n",
    "#         })\n",
    "\n",
    "    # if i > 2:\n",
    "    #     word3 = sent[i - 3][0]\n",
    "    #     word2 = sent[i - 2][0]\n",
    "    #     word1 = sent[i - 1][0]\n",
    "    #     words = word1 + word2 + word3 + word\n",
    "    #     features.update({\n",
    "    #         '-3:word': word3,\n",
    "    #         '-3:words': words,\n",
    "    #         '-3:word.isdigit()': word3.isdigit(),\n",
    "    #         '-3:word.isspace()': word3.isalpha(),\n",
    "    #     })\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        words = word1 + word\n",
    "        features.update({\n",
    "            '+1:word': word1,\n",
    "            '+1:words': words,\n",
    "            '+1:word.isdigit()': word1.isdigit(),\n",
    "            '+1:word.isspace()': word1.isalpha(),\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "#     if i < len(sent)-2:\n",
    "#         word2 = sent[i + 2][0]\n",
    "#         word1 = sent[i + 1][0]\n",
    "#         words = word + word1 + word2\n",
    "#         features.update({\n",
    "#             '+2:word': word2,\n",
    "#             '+2:words': words,\n",
    "#             '+2:word.isdigit()': word2.isdigit(),\n",
    "#         })\n",
    "\n",
    "    # if i < len(sent)-3:\n",
    "    #     word3 = sent[i + 3][0]\n",
    "    #     word2 = sent[i + 2][0]\n",
    "    #     word1 = sent[i + 1][0]\n",
    "    #     words = word + word1 + word2 + word3\n",
    "    #     features.update({\n",
    "    #         '+3:word': word3,\n",
    "    #         '+3:words': words,\n",
    "    #         '+3:word.isdigit()': word3.isdigit(),\n",
    "    #     })\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "quantitative-security",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent2features(sent):\n",
    "    return [word2features(sent, i) for i in range(len(sent))]\n",
    "\n",
    "\n",
    "def sent2labels(sent):\n",
    "    return [ele[-1] for ele in sent]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "prime-blackjack",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 32000/32000 [00:03<00:00, 10023.82it/s]\n",
      "100%|██████████| 32000/32000 [00:00<00:00, 197827.91it/s]\n",
      "100%|██████████| 8000/8000 [00:00<00:00, 8029.21it/s]\n",
      "100%|██████████| 8000/8000 [00:00<00:00, 225008.76it/s]\n"
     ]
    }
   ],
   "source": [
    "# 生成特征\n",
    "X_train = [sent2features(s) for s in tqdm(train)]\n",
    "y_train = [sent2labels(s) for s in tqdm(train)]\n",
    "\n",
    "X_dev = [sent2features(s) for s in tqdm(valid)]\n",
    "y_dev = [sent2labels(s) for s in tqdm(valid)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "wrong-permission",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'bias': 1.0,\n",
       "  'word': '毕',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  'BOS': True,\n",
       "  '+1:word': '加',\n",
       "  '+1:words': '加毕',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '加',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '毕',\n",
       "  '-1:words': '毕加',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '索',\n",
       "  '+1:words': '索加',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '索',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '加',\n",
       "  '-1:words': '加索',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '旗',\n",
       "  '+1:words': '旗索',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '旗',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '索',\n",
       "  '-1:words': '索旗',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '下',\n",
       "  '+1:words': '下旗',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '下',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '旗',\n",
       "  '-1:words': '旗下',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '优',\n",
       "  '+1:words': '优下',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '优',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '下',\n",
       "  '-1:words': '下优',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '尚',\n",
       "  '+1:words': '尚优',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '尚',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '优',\n",
       "  '-1:words': '优尚',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '钢',\n",
       "  '+1:words': '钢尚',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '钢',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '尚',\n",
       "  '-1:words': '尚钢',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '笔',\n",
       "  '+1:words': '笔钢',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '笔',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '钢',\n",
       "  '-1:words': '钢笔',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': 'T',\n",
       "  '+1:words': 'T笔',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': 'T',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '笔',\n",
       "  '-1:words': '笔T',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '6',\n",
       "  '+1:words': '6T',\n",
       "  '+1:word.isdigit()': True,\n",
       "  '+1:word.isspace()': False},\n",
       " {'bias': 1.0,\n",
       "  'word': '6',\n",
       "  'word.isdigit()': True,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': False,\n",
       "  '-1:word': 'T',\n",
       "  '-1:words': 'T6',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '美',\n",
       "  '+1:words': '美6',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '美',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '6',\n",
       "  '-1:words': '6美',\n",
       "  '-1:word.isdigit()': True,\n",
       "  '-1:word.isspace()': False,\n",
       "  '+1:word': '工',\n",
       "  '+1:words': '工美',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '工',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '美',\n",
       "  '-1:words': '美工',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '笔',\n",
       "  '+1:words': '笔工',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '笔',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '工',\n",
       "  '-1:words': '工笔',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '弯',\n",
       "  '+1:words': '弯笔',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '弯',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '笔',\n",
       "  '-1:words': '笔弯',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '尖',\n",
       "  '+1:words': '尖弯',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '尖',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '弯',\n",
       "  '-1:words': '弯尖',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '钢',\n",
       "  '+1:words': '钢尖',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '钢',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '尖',\n",
       "  '-1:words': '尖钢',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '笔',\n",
       "  '+1:words': '笔钢',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '笔',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '钢',\n",
       "  '-1:words': '钢笔',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '学',\n",
       "  '+1:words': '学笔',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '学',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '笔',\n",
       "  '-1:words': '笔学',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '生',\n",
       "  '+1:words': '生学',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '生',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '学',\n",
       "  '-1:words': '学生',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '专',\n",
       "  '+1:words': '专生',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '专',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '生',\n",
       "  '-1:words': '生专',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '用',\n",
       "  '+1:words': '用专',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '用',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '专',\n",
       "  '-1:words': '专用',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '男',\n",
       "  '+1:words': '男用',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '男',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '用',\n",
       "  '-1:words': '用男',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '士',\n",
       "  '+1:words': '士男',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '士',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '男',\n",
       "  '-1:words': '男士',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '钢',\n",
       "  '+1:words': '钢士',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '钢',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '士',\n",
       "  '-1:words': '士钢',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '笔',\n",
       "  '+1:words': '笔钢',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '笔',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '钢',\n",
       "  '-1:words': '钢笔',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '练',\n",
       "  '+1:words': '练笔',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '练',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '笔',\n",
       "  '-1:words': '笔练',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '字',\n",
       "  '+1:words': '字练',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '字',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '练',\n",
       "  '-1:words': '练字',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '钢',\n",
       "  '+1:words': '钢字',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '钢',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '字',\n",
       "  '-1:words': '字钢',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '笔',\n",
       "  '+1:words': '笔钢',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '笔',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '钢',\n",
       "  '-1:words': '钢笔',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '女',\n",
       "  '+1:words': '女笔',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '女',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '笔',\n",
       "  '-1:words': '笔女',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '成',\n",
       "  '+1:words': '成女',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '成',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '女',\n",
       "  '-1:words': '女成',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '人',\n",
       "  '+1:words': '人成',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '人',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '成',\n",
       "  '-1:words': '成人',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '书',\n",
       "  '+1:words': '书人',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '书',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '人',\n",
       "  '-1:words': '人书',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '法',\n",
       "  '+1:words': '法书',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '法',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '书',\n",
       "  '-1:words': '书法',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '送',\n",
       "  '+1:words': '送法',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '送',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '法',\n",
       "  '-1:words': '法送',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '礼',\n",
       "  '+1:words': '礼送',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '礼',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '送',\n",
       "  '-1:words': '送礼',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '刻',\n",
       "  '+1:words': '刻礼',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '刻',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '礼',\n",
       "  '-1:words': '礼刻',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '字',\n",
       "  '+1:words': '字刻',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '字',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '刻',\n",
       "  '-1:words': '刻字',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '签',\n",
       "  '+1:words': '签字',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '签',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '字',\n",
       "  '-1:words': '字签',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '字',\n",
       "  '+1:words': '字签',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '字',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '签',\n",
       "  '-1:words': '签字',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '墨',\n",
       "  '+1:words': '墨字',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '墨',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '字',\n",
       "  '-1:words': '字墨',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '囊',\n",
       "  '+1:words': '囊墨',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '囊',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '墨',\n",
       "  '-1:words': '墨囊',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '钢',\n",
       "  '+1:words': '钢囊',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '钢',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '囊',\n",
       "  '-1:words': '囊钢',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '笔',\n",
       "  '+1:words': '笔钢',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '笔',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '钢',\n",
       "  '-1:words': '钢笔',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '礼',\n",
       "  '+1:words': '礼笔',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '礼',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '笔',\n",
       "  '-1:words': '笔礼',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '盒',\n",
       "  '+1:words': '盒礼',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '盒',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '礼',\n",
       "  '-1:words': '礼盒',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '套',\n",
       "  '+1:words': '套盒',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '套',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '盒',\n",
       "  '-1:words': '盒套',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': ' ',\n",
       "  '+1:words': ' 套',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': False},\n",
       " {'bias': 1.0,\n",
       "  'word': ' ',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': True,\n",
       "  'word.isalpha()': False,\n",
       "  '-1:word': '套',\n",
       "  '-1:words': '套 ',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '银',\n",
       "  '+1:words': '银 ',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '银',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': ' ',\n",
       "  '-1:words': ' 银',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': False,\n",
       "  '+1:word': '夹',\n",
       "  '+1:words': '夹银',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '夹',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '银',\n",
       "  '-1:words': '银夹',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '白',\n",
       "  '+1:words': '白夹',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '白',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '夹',\n",
       "  '-1:words': '夹白',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '色',\n",
       "  '+1:words': '色白',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '色',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '白',\n",
       "  '-1:words': '白色',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '+',\n",
       "  '+1:words': '+色',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': False},\n",
       " {'bias': 1.0,\n",
       "  'word': '+',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': False,\n",
       "  '-1:word': '色',\n",
       "  '-1:words': '色+',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '蓝',\n",
       "  '+1:words': '蓝+',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '蓝',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '+',\n",
       "  '-1:words': '+蓝',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': False,\n",
       "  '+1:word': '黑',\n",
       "  '+1:words': '黑蓝',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '黑',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '蓝',\n",
       "  '-1:words': '蓝黑',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '墨',\n",
       "  '+1:words': '墨黑',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '墨',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '黑',\n",
       "  '-1:words': '黑墨',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '水',\n",
       "  '+1:words': '水墨',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '水',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '墨',\n",
       "  '-1:words': '墨水',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': ' ',\n",
       "  '+1:words': ' 水',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': False},\n",
       " {'bias': 1.0,\n",
       "  'word': ' ',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': True,\n",
       "  'word.isalpha()': False,\n",
       "  '-1:word': '水',\n",
       "  '-1:words': '水 ',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '0',\n",
       "  '+1:words': '0 ',\n",
       "  '+1:word.isdigit()': True,\n",
       "  '+1:word.isspace()': False},\n",
       " {'bias': 1.0,\n",
       "  'word': '0',\n",
       "  'word.isdigit()': True,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': False,\n",
       "  '-1:word': ' ',\n",
       "  '-1:words': ' 0',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': False,\n",
       "  '+1:word': '.',\n",
       "  '+1:words': '.0',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': False},\n",
       " {'bias': 1.0,\n",
       "  'word': '.',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': False,\n",
       "  '-1:word': '0',\n",
       "  '-1:words': '0.',\n",
       "  '-1:word.isdigit()': True,\n",
       "  '-1:word.isspace()': False,\n",
       "  '+1:word': '3',\n",
       "  '+1:words': '3.',\n",
       "  '+1:word.isdigit()': True,\n",
       "  '+1:word.isspace()': False},\n",
       " {'bias': 1.0,\n",
       "  'word': '3',\n",
       "  'word.isdigit()': True,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': False,\n",
       "  '-1:word': '.',\n",
       "  '-1:words': '.3',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': False,\n",
       "  '+1:word': '8',\n",
       "  '+1:words': '83',\n",
       "  '+1:word.isdigit()': True,\n",
       "  '+1:word.isspace()': False},\n",
       " {'bias': 1.0,\n",
       "  'word': '8',\n",
       "  'word.isdigit()': True,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': False,\n",
       "  '-1:word': '3',\n",
       "  '-1:words': '38',\n",
       "  '-1:word.isdigit()': True,\n",
       "  '-1:word.isspace()': False,\n",
       "  '+1:word': 'm',\n",
       "  '+1:words': 'm8',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': 'm',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '8',\n",
       "  '-1:words': '8m',\n",
       "  '-1:word.isdigit()': True,\n",
       "  '-1:word.isspace()': False,\n",
       "  '+1:word': 'm',\n",
       "  '+1:words': 'mm',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': 'm',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': 'm',\n",
       "  '-1:words': 'mm',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '+',\n",
       "  '+1:words': '+m',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': False},\n",
       " {'bias': 1.0,\n",
       "  'word': '+',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': False,\n",
       "  '-1:word': 'm',\n",
       "  '-1:words': 'm+',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '0',\n",
       "  '+1:words': '0+',\n",
       "  '+1:word.isdigit()': True,\n",
       "  '+1:word.isspace()': False},\n",
       " {'bias': 1.0,\n",
       "  'word': '0',\n",
       "  'word.isdigit()': True,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': False,\n",
       "  '-1:word': '+',\n",
       "  '-1:words': '+0',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': False,\n",
       "  '+1:word': '.',\n",
       "  '+1:words': '.0',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': False},\n",
       " {'bias': 1.0,\n",
       "  'word': '.',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': False,\n",
       "  '-1:word': '0',\n",
       "  '-1:words': '0.',\n",
       "  '-1:word.isdigit()': True,\n",
       "  '-1:word.isspace()': False,\n",
       "  '+1:word': '7',\n",
       "  '+1:words': '7.',\n",
       "  '+1:word.isdigit()': True,\n",
       "  '+1:word.isspace()': False},\n",
       " {'bias': 1.0,\n",
       "  'word': '7',\n",
       "  'word.isdigit()': True,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': False,\n",
       "  '-1:word': '.',\n",
       "  '-1:words': '.7',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': False,\n",
       "  '+1:word': 'm',\n",
       "  '+1:words': 'm7',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': 'm',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '7',\n",
       "  '-1:words': '7m',\n",
       "  '-1:word.isdigit()': True,\n",
       "  '-1:word.isspace()': False,\n",
       "  '+1:word': 'm',\n",
       "  '+1:words': 'mm',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': 'm',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': 'm',\n",
       "  '-1:words': 'mm',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '【',\n",
       "  '+1:words': '【m',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': False},\n",
       " {'bias': 1.0,\n",
       "  'word': '【',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': False,\n",
       "  '-1:word': 'm',\n",
       "  '-1:words': 'm【',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '送',\n",
       "  '+1:words': '送【',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '送',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '【',\n",
       "  '-1:words': '【送',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': False,\n",
       "  '+1:word': '笔',\n",
       "  '+1:words': '笔送',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '笔',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '送',\n",
       "  '-1:words': '送笔',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '袋',\n",
       "  '+1:words': '袋笔',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '袋',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '笔',\n",
       "  '-1:words': '笔袋',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '+',\n",
       "  '+1:words': '+袋',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': False},\n",
       " {'bias': 1.0,\n",
       "  'word': '+',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': False,\n",
       "  '-1:word': '袋',\n",
       "  '-1:words': '袋+',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '墨',\n",
       "  '+1:words': '墨+',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '墨',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '+',\n",
       "  '-1:words': '+墨',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': False,\n",
       "  '+1:word': '囊',\n",
       "  '+1:words': '囊墨',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '囊',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '墨',\n",
       "  '-1:words': '墨囊',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '*',\n",
       "  '+1:words': '*囊',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': False},\n",
       " {'bias': 1.0,\n",
       "  'word': '*',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': False,\n",
       "  '-1:word': '囊',\n",
       "  '-1:words': '囊*',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  '+1:word': '1',\n",
       "  '+1:words': '1*',\n",
       "  '+1:word.isdigit()': True,\n",
       "  '+1:word.isspace()': False},\n",
       " {'bias': 1.0,\n",
       "  'word': '1',\n",
       "  'word.isdigit()': True,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': False,\n",
       "  '-1:word': '*',\n",
       "  '-1:words': '*1',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': False,\n",
       "  '+1:word': '2',\n",
       "  '+1:words': '21',\n",
       "  '+1:word.isdigit()': True,\n",
       "  '+1:word.isspace()': False},\n",
       " {'bias': 1.0,\n",
       "  'word': '2',\n",
       "  'word.isdigit()': True,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': False,\n",
       "  '-1:word': '1',\n",
       "  '-1:words': '12',\n",
       "  '-1:word.isdigit()': True,\n",
       "  '-1:word.isspace()': False,\n",
       "  '+1:word': '+',\n",
       "  '+1:words': '+2',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': False},\n",
       " {'bias': 1.0,\n",
       "  'word': '+',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': False,\n",
       "  '-1:word': '2',\n",
       "  '-1:words': '2+',\n",
       "  '-1:word.isdigit()': True,\n",
       "  '-1:word.isspace()': False,\n",
       "  '+1:word': '贺',\n",
       "  '+1:words': '贺+',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '贺',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '+',\n",
       "  '-1:words': '+贺',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': False,\n",
       "  '+1:word': '卡',\n",
       "  '+1:words': '卡贺',\n",
       "  '+1:word.isdigit()': False,\n",
       "  '+1:word.isspace()': True},\n",
       " {'bias': 1.0,\n",
       "  'word': '卡',\n",
       "  'word.isdigit()': False,\n",
       "  'word.isspace()': False,\n",
       "  'word.isalpha()': True,\n",
       "  '-1:word': '贺',\n",
       "  '-1:words': '贺卡',\n",
       "  '-1:word.isdigit()': False,\n",
       "  '-1:word.isspace()': True,\n",
       "  'EOS': True}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "reserved-latest",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading training data to CRFsuite: 100%|██████████| 32000/32000 [00:17<00:00, 1860.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Feature generation\n",
      "type: CRF1d\n",
      "feature.minfreq: 0.000000\n",
      "feature.possible_states: 0\n",
      "feature.possible_transitions: 1\n",
      "0....1....2....3....4....5....6....7....8....9....10\n",
      "Number of features: 729973\n",
      "Seconds required: 4.920\n",
      "\n",
      "L-BFGS optimization\n",
      "c1: 0.250000\n",
      "c2: 0.018000\n",
      "num_memories: 6\n",
      "max_iterations: 100\n",
      "epsilon: 0.000010\n",
      "stop: 10\n",
      "delta: 0.000010\n",
      "linesearch: MoreThuente\n",
      "linesearch.max_iterations: 20\n",
      "\n",
      "Iter 1   time=93.28 loss=7610708.28 active=717990 feature_norm=1.00\n",
      "Iter 2   time=96.01 loss=7462314.02 active=712997 feature_norm=8.14\n",
      "Iter 3   time=48.23 loss=5971845.88 active=706005 feature_norm=7.29\n",
      "Iter 4   time=47.82 loss=5763859.18 active=717400 feature_norm=6.56\n",
      "Iter 5   time=48.08 loss=5298840.34 active=714661 feature_norm=6.93\n",
      "Iter 6   time=48.04 loss=5078078.89 active=714850 feature_norm=10.80\n",
      "Iter 7   time=47.46 loss=4505330.91 active=714735 feature_norm=11.59\n",
      "Iter 8   time=96.92 loss=4373063.73 active=719234 feature_norm=11.03\n",
      "Iter 9   time=48.44 loss=4102882.89 active=722290 feature_norm=11.81\n",
      "Iter 10  time=48.57 loss=3854988.27 active=723528 feature_norm=12.77\n",
      "Iter 11  time=48.63 loss=3735255.82 active=721477 feature_norm=14.78\n",
      "Iter 12  time=48.30 loss=3461627.95 active=723411 feature_norm=15.62\n",
      "Iter 13  time=48.05 loss=3255049.57 active=724099 feature_norm=18.23\n",
      "Iter 14  time=49.23 loss=3041969.01 active=725604 feature_norm=19.37\n",
      "Iter 15  time=50.68 loss=2681449.33 active=722276 feature_norm=23.47\n",
      "Iter 16  time=99.29 loss=2460600.83 active=721691 feature_norm=27.58\n",
      "Iter 17  time=48.74 loss=2248817.04 active=719344 feature_norm=32.75\n",
      "Iter 18  time=49.04 loss=2119985.07 active=723727 feature_norm=35.08\n",
      "Iter 19  time=48.88 loss=1991967.97 active=723863 feature_norm=36.59\n",
      "Iter 20  time=48.41 loss=1899341.98 active=723642 feature_norm=39.97\n",
      "Iter 21  time=48.81 loss=1778569.55 active=723155 feature_norm=43.63\n",
      "Iter 22  time=49.24 loss=1670178.94 active=723816 feature_norm=46.44\n",
      "Iter 23  time=48.73 loss=1561255.58 active=723690 feature_norm=49.30\n",
      "Iter 24  time=48.89 loss=1476949.07 active=722709 feature_norm=54.33\n",
      "Iter 25  time=48.92 loss=1425639.68 active=723786 feature_norm=53.77\n",
      "Iter 26  time=49.79 loss=1387405.93 active=724837 feature_norm=55.39\n",
      "Iter 27  time=50.28 loss=1319500.14 active=723623 feature_norm=58.16\n",
      "Iter 28  time=50.16 loss=1311160.67 active=720470 feature_norm=63.96\n",
      "Iter 29  time=49.23 loss=1226861.27 active=721802 feature_norm=63.25\n",
      "Iter 30  time=50.26 loss=1203828.13 active=723397 feature_norm=64.53\n",
      "Iter 31  time=98.66 loss=1124062.04 active=714042 feature_norm=72.34\n",
      "Iter 32  time=49.15 loss=1086792.03 active=714722 feature_norm=78.97\n",
      "Iter 33  time=48.58 loss=1034348.16 active=717464 feature_norm=83.22\n",
      "Iter 34  time=48.43 loss=1003757.31 active=719656 feature_norm=86.47\n",
      "Iter 35  time=48.77 loss=950294.50 active=711545 feature_norm=91.92\n",
      "Iter 36  time=49.01 loss=898353.59 active=707362 feature_norm=100.45\n",
      "Iter 37  time=48.64 loss=850288.47 active=702885 feature_norm=109.75\n",
      "Iter 38  time=98.25 loss=820344.12 active=701407 feature_norm=117.36\n",
      "Iter 39  time=49.04 loss=809047.40 active=702832 feature_norm=115.97\n",
      "Iter 40  time=48.73 loss=785750.51 active=702453 feature_norm=121.09\n",
      "Iter 41  time=98.28 loss=762052.96 active=700584 feature_norm=128.01\n",
      "Iter 42  time=49.16 loss=750994.85 active=697949 feature_norm=133.87\n",
      "Iter 43  time=49.94 loss=734387.58 active=700538 feature_norm=135.92\n",
      "Iter 44  time=49.18 loss=720548.69 active=698292 feature_norm=139.95\n",
      "Iter 45  time=49.15 loss=699812.21 active=695466 feature_norm=147.16\n",
      "Iter 46  time=48.97 loss=668575.56 active=673203 feature_norm=168.45\n",
      "Iter 47  time=98.12 loss=658093.59 active=681674 feature_norm=172.18\n",
      "Iter 48  time=49.52 loss=645697.82 active=681765 feature_norm=176.98\n",
      "Iter 49  time=49.39 loss=617510.01 active=669946 feature_norm=199.41\n",
      "Iter 50  time=48.63 loss=602879.63 active=674532 feature_norm=206.21\n",
      "Iter 51  time=48.73 loss=588273.55 active=671411 feature_norm=214.58\n",
      "Iter 52  time=48.79 loss=576060.61 active=661013 feature_norm=238.09\n",
      "Iter 53  time=48.71 loss=553495.30 active=668354 feature_norm=243.89\n",
      "Iter 54  time=49.15 loss=546472.30 active=670100 feature_norm=247.43\n",
      "Iter 55  time=49.26 loss=523707.80 active=661310 feature_norm=279.24\n",
      "Iter 56  time=146.86 loss=519732.38 active=664643 feature_norm=275.23\n",
      "Iter 57  time=49.27 loss=516989.96 active=666636 feature_norm=274.89\n",
      "Iter 58  time=48.47 loss=513343.48 active=666648 feature_norm=276.41\n",
      "Iter 59  time=48.66 loss=504989.22 active=664004 feature_norm=281.69\n",
      "Iter 60  time=98.61 loss=496179.47 active=653613 feature_norm=304.42\n",
      "Iter 61  time=48.79 loss=478133.29 active=654329 feature_norm=315.65\n",
      "Iter 62  time=48.98 loss=466805.82 active=634835 feature_norm=332.49\n",
      "Iter 63  time=97.61 loss=461166.17 active=631865 feature_norm=357.72\n",
      "Iter 64  time=48.44 loss=451069.25 active=636201 feature_norm=350.44\n",
      "Iter 65  time=47.77 loss=446761.64 active=634271 feature_norm=355.84\n",
      "Iter 66  time=96.81 loss=432510.55 active=628399 feature_norm=386.45\n",
      "Iter 67  time=96.85 loss=425987.47 active=628985 feature_norm=406.80\n",
      "Iter 68  time=48.08 loss=412599.47 active=629236 feature_norm=435.70\n",
      "Iter 69  time=47.78 loss=399463.38 active=623398 feature_norm=481.16\n",
      "Iter 70  time=47.35 loss=387419.84 active=621998 feature_norm=514.89\n",
      "Iter 71  time=47.93 loss=375197.37 active=617070 feature_norm=556.33\n",
      "Iter 72  time=96.28 loss=374037.54 active=616215 feature_norm=579.96\n",
      "Iter 73  time=48.42 loss=361464.81 active=616966 feature_norm=606.88\n",
      "Iter 74  time=48.09 loss=355141.44 active=614791 feature_norm=637.63\n",
      "Iter 75  time=48.14 loss=347902.91 active=610200 feature_norm=691.37\n",
      "Iter 76  time=48.12 loss=342990.84 active=609482 feature_norm=717.51\n",
      "Iter 77  time=47.96 loss=340294.99 active=609729 feature_norm=725.48\n",
      "Iter 78  time=47.92 loss=336856.87 active=597372 feature_norm=746.56\n",
      "Iter 79  time=47.93 loss=334039.85 active=591079 feature_norm=758.13\n",
      "Iter 80  time=47.64 loss=331327.61 active=584207 feature_norm=771.21\n",
      "Iter 81  time=47.54 loss=329352.92 active=579746 feature_norm=782.99\n",
      "Iter 82  time=47.57 loss=327243.31 active=574022 feature_norm=793.03\n",
      "Iter 83  time=48.30 loss=325718.22 active=568452 feature_norm=794.22\n",
      "Iter 84  time=48.03 loss=323948.12 active=560925 feature_norm=798.45\n",
      "Iter 85  time=48.12 loss=322463.13 active=550250 feature_norm=813.56\n",
      "Iter 86  time=47.67 loss=321126.87 active=551442 feature_norm=817.11\n",
      "Iter 87  time=47.82 loss=320280.15 active=551881 feature_norm=819.22\n",
      "Iter 88  time=48.01 loss=319337.29 active=549374 feature_norm=823.05\n",
      "Iter 89  time=48.31 loss=317668.69 active=532253 feature_norm=835.58\n",
      "Iter 90  time=48.19 loss=316830.78 active=529827 feature_norm=837.52\n",
      "Iter 91  time=47.80 loss=316223.43 active=530265 feature_norm=839.06\n",
      "Iter 92  time=47.62 loss=315260.98 active=526135 feature_norm=843.49\n",
      "Iter 93  time=47.34 loss=314398.55 active=523670 feature_norm=845.66\n",
      "Iter 94  time=48.04 loss=313452.77 active=517512 feature_norm=849.43\n",
      "Iter 95  time=48.01 loss=312631.64 active=515794 feature_norm=853.14\n",
      "Iter 96  time=47.27 loss=311907.75 active=516170 feature_norm=853.83\n",
      "Iter 97  time=46.98 loss=311319.68 active=514595 feature_norm=855.04\n",
      "Iter 98  time=47.56 loss=310455.95 active=511050 feature_norm=856.51\n",
      "Iter 99  time=47.73 loss=309462.73 active=506623 feature_norm=858.43\n",
      "Iter 100 time=94.06 loss=309080.60 active=504679 feature_norm=859.57\n",
      "L-BFGS terminated with the maximum number of iterations\n",
      "Total seconds required for training: 5629.400\n",
      "\n",
      "Storing the model\n",
      "Number of active features: 504679 (729973)\n",
      "Number of active attributes: 219504 (338159)\n",
      "Number of active labels: 105 (105)\n",
      "Writing labels\n",
      "Writing attributes\n",
      "Writing feature references for transitions\n",
      "Writing feature references for attributes\n",
      "Seconds required: 0.200\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=True,\n",
       "    averaging=None, c=None, c1=0.25, c2=0.018, calibration_candidates=None,\n",
       "    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
       "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
       "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=True)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# **表示该位置接受任意多个关键字（keyword）参数，在函数**位置上转化为词典 [key:value, key:value ]\n",
    "crf_model = sklearn_crfsuite.CRF(algorithm='lbfgs',c1=0.25,c2=0.018,max_iterations=100,\n",
    "                                 all_possible_transitions=True,verbose=True)\n",
    "crf_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "adjacent-dress",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         B-1      0.891     0.896     0.893      5062\n",
      "         I-1      0.883     0.922     0.902     11806\n",
      "        B-10      0.581     0.513     0.544      1678\n",
      "        I-10      0.550     0.581     0.565      4082\n",
      "        B-11      0.794     0.804     0.799     12128\n",
      "        I-11      0.776     0.788     0.782     18511\n",
      "        B-12      0.805     0.825     0.815      2522\n",
      "        I-12      0.793     0.828     0.810      3539\n",
      "        B-13      0.721     0.724     0.723     12871\n",
      "        I-13      0.699     0.700     0.699     18940\n",
      "        B-14      0.886     0.913     0.899      4429\n",
      "        I-14      0.874     0.899     0.886      5099\n",
      "        B-15      0.645     0.719     0.680       139\n",
      "        I-15      0.683     0.667     0.675       171\n",
      "        B-16      0.908     0.909     0.908      4567\n",
      "        I-16      0.902     0.923     0.912      5684\n",
      "        B-17      0.667     0.400     0.500         5\n",
      "        I-17      0.750     0.500     0.600         6\n",
      "        B-18      0.782     0.807     0.794     10764\n",
      "        I-18      0.806     0.857     0.831     28165\n",
      "        B-19      0.312     0.172     0.222        29\n",
      "        I-19      0.360     0.184     0.243        49\n",
      "         B-2      0.329     0.210     0.256       572\n",
      "         I-2      0.331     0.246     0.282      2285\n",
      "        B-20      0.470     0.336     0.392       116\n",
      "        I-20      0.345     0.254     0.292       268\n",
      "        B-21      0.287     0.357     0.318        98\n",
      "        I-21      0.344     0.478     0.400       467\n",
      "        B-22      0.395     0.260     0.313      1874\n",
      "        I-22      0.388     0.259     0.311      2793\n",
      "        B-23      0.000     0.000     0.000         2\n",
      "        I-23      0.000     0.000     0.000         2\n",
      "        B-24      0.000     0.000     0.000         1\n",
      "        I-24      0.000     0.000     0.000         2\n",
      "        B-25      0.000     0.000     0.000        10\n",
      "        I-25      0.000     0.000     0.000        10\n",
      "        B-26      0.000     0.000     0.000         0\n",
      "        I-26      0.000     0.000     0.000         0\n",
      "        B-28      0.000     0.000     0.000         6\n",
      "        I-28      0.000     0.000     0.000        16\n",
      "        B-29      0.745     0.750     0.748       883\n",
      "        I-29      0.705     0.754     0.729      1416\n",
      "         B-3      0.539     0.502     0.520      1829\n",
      "         I-3      0.546     0.590     0.567      8267\n",
      "        B-30      0.327     0.145     0.201       117\n",
      "        I-30      0.382     0.182     0.247       159\n",
      "        B-31      0.381     0.286     0.327       168\n",
      "        I-31      0.344     0.242     0.284       219\n",
      "        B-32      0.000     0.000     0.000         6\n",
      "        I-32      0.000     0.000     0.000         7\n",
      "        B-33      0.000     0.000     0.000         2\n",
      "        I-33      0.000     0.000     0.000         2\n",
      "        B-34      0.000     0.000     0.000        45\n",
      "        I-34      0.000     0.000     0.000        48\n",
      "        B-35      0.000     0.000     0.000         1\n",
      "        I-35      0.000     0.000     0.000         0\n",
      "        B-36      0.560     0.481     0.518       694\n",
      "        I-36      0.538     0.399     0.458      1575\n",
      "        B-37      0.794     0.823     0.808      3063\n",
      "        I-37      0.775     0.767     0.771      4643\n",
      "        B-38      0.737     0.738     0.737      6176\n",
      "        I-38      0.765     0.840     0.801     25734\n",
      "        B-39      0.424     0.315     0.361      1022\n",
      "        I-39      0.455     0.420     0.437      5023\n",
      "         B-4      0.811     0.854     0.832     33435\n",
      "         I-4      0.837     0.893     0.864     62533\n",
      "        B-40      0.701     0.611     0.653      6406\n",
      "        I-40      0.704     0.595     0.645     10472\n",
      "        B-41      0.213     0.114     0.148        88\n",
      "        I-41      0.211     0.114     0.148       105\n",
      "        B-42      0.000     0.000     0.000         3\n",
      "        I-42      0.000     0.000     0.000         3\n",
      "        B-43      0.000     0.000     0.000        13\n",
      "        I-43      0.000     0.000     0.000        14\n",
      "        B-44      0.667     0.333     0.444         6\n",
      "        I-44      0.667     0.250     0.364         8\n",
      "        B-46      1.000     0.125     0.222         8\n",
      "        I-46      1.000     0.059     0.111        17\n",
      "        B-47      0.336     0.140     0.197       265\n",
      "        I-47      0.361     0.184     0.244       397\n",
      "        B-48      0.357     0.143     0.204        35\n",
      "        I-48      0.312     0.119     0.172        42\n",
      "        B-49      0.437     0.247     0.316       295\n",
      "        I-49      0.411     0.264     0.321       440\n",
      "         B-5      0.760     0.752     0.756      8160\n",
      "         I-5      0.733     0.718     0.726     10348\n",
      "        B-50      0.493     0.442     0.466        77\n",
      "        I-50      0.493     0.553     0.521       123\n",
      "        B-51      1.000     0.250     0.400         4\n",
      "        I-51      1.000     0.250     0.400         4\n",
      "        B-52      0.632     0.308     0.414        39\n",
      "        I-52      0.667     0.292     0.406        48\n",
      "        B-53      0.000     0.000     0.000         0\n",
      "        I-53      0.000     0.000     0.000         0\n",
      "        B-54      0.713     0.613     0.659      1177\n",
      "        I-54      0.792     0.760     0.776      4207\n",
      "         B-6      0.745     0.630     0.682       324\n",
      "         I-6      0.727     0.582     0.647       577\n",
      "         B-7      0.899     0.895     0.897      4989\n",
      "         I-7      0.889     0.872     0.880      6042\n",
      "         B-8      0.899     0.896     0.897      3651\n",
      "         I-8      0.886     0.873     0.879      4709\n",
      "         B-9      0.575     0.524     0.548      2576\n",
      "         I-9      0.565     0.513     0.538      3823\n",
      "\n",
      "   micro avg      0.772     0.780     0.776    385330\n",
      "   macro avg      0.485     0.403     0.424    385330\n",
      "weighted avg      0.765     0.780     0.772    385330\n",
      "\n"
     ]
    }
   ],
   "source": [
    "labels=list(crf_model.classes_)\n",
    "labels.remove(\"O\")\n",
    "y_pred = crf_model.predict(X_dev)\n",
    "metrics.flat_f1_score(y_dev, y_pred,\n",
    "                      average='weighted', labels=labels)\n",
    "sorted_labels = sorted(labels,key=lambda name: (name[1:], name[0]))\n",
    "print(metrics.flat_classification_report(\n",
    "    y_dev, y_pred, labels=sorted_labels, digits=3\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "liked-exception",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['./product_crf_model.joblib']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "joblib.dump(crf_model, \"./product_crf_model.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "expensive-rogers",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('O', 'B-37'),\n",
       " ('P', 'I-37'),\n",
       " ('P', 'I-37'),\n",
       " ('O', 'I-37'),\n",
       " ('闪', 'B-11'),\n",
       " ('充', 'I-11'),\n",
       " ('充', 'B-4'),\n",
       " ('电', 'I-4'),\n",
       " ('器', 'I-4'),\n",
       " (' ', 'O'),\n",
       " ('X', 'B-38'),\n",
       " ('9', 'I-38'),\n",
       " ('0', 'I-38'),\n",
       " ('7', 'I-38'),\n",
       " ('0', 'I-38'),\n",
       " (' ', 'O'),\n",
       " ('X', 'B-38'),\n",
       " ('9', 'I-38'),\n",
       " ('0', 'I-38'),\n",
       " ('7', 'I-38'),\n",
       " ('7', 'I-38'),\n",
       " (' ', 'O'),\n",
       " ('R', 'B-38'),\n",
       " ('5', 'I-38'),\n",
       " (' ', 'O'),\n",
       " ('快', 'B-4'),\n",
       " ('充', 'I-4'),\n",
       " ('头', 'I-4'),\n",
       " ('通', 'B-11'),\n",
       " ('用', 'I-11'),\n",
       " ('手', 'B-40'),\n",
       " ('机', 'I-40'),\n",
       " ('数', 'B-4'),\n",
       " ('据', 'I-4'),\n",
       " ('线', 'I-4'),\n",
       " (' ', 'O'),\n",
       " ('套', 'O'),\n",
       " ('餐', 'O'),\n",
       " ('【', 'O'),\n",
       " ('2', 'B-18'),\n",
       " ('.', 'I-18'),\n",
       " ('4', 'I-18'),\n",
       " ('充', 'B-4'),\n",
       " ('电', 'I-4'),\n",
       " ('头', 'I-4'),\n",
       " ('+', 'O'),\n",
       " ('数', 'B-4'),\n",
       " ('据', 'I-4'),\n",
       " ('线', 'I-4'),\n",
       " (' ', 'O'),\n",
       " ('】', 'O'),\n",
       " (' ', 'O'),\n",
       " ('安', 'B-37'),\n",
       " ('卓', 'I-37'),\n",
       " (' ', 'O'),\n",
       " ('1', 'B-18'),\n",
       " ('.', 'I-18'),\n",
       " ('5', 'I-18'),\n",
       " ('m', 'I-18')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = 'OPPO闪充充电器 X9070 X9077 R5 快充头通用手机数据线 套餐【2.4充电头+数据线 】 安卓 1.5m'\n",
    "\n",
    "NER_tagger = joblib.load('./product_crf_model.joblib')\n",
    "list_result = []\n",
    "new_sents = re.split(u'(。|！|\\!|？|\\?)', text)\n",
    "sents_feature = [sent2features(sent) for sent in new_sents]\n",
    "y_pred = NER_tagger.predict(sents_feature)\n",
    "for sent, ner_tag in zip(new_sents, y_pred):\n",
    "    for word, tag in zip(sent, ner_tag):\n",
    "        list_result.append((word,tag))\n",
    "list_result    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "nominated-carol",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "executive-mediterranean",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.22.2'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sklearn.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cce23020-52ba-4819-8855-59804cc41adb",
   "metadata": {},
   "source": [
    "## submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dbc4f354-f1b9-4cf6-a23d-96f2154cc270",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_file='data/preliminary_test_a/sample_per_line_preliminary_A.txt'\n",
    "test_sents=[]\n",
    "with open(test_file, 'r', encoding='utf-8') as f:\n",
    "    for line in f.read().split('\\n'):\n",
    "        test_sents.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c57dd110-c26e-41ec-b3ef-355c2829b84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sents_feature = [sent2features(sent) for sent in test_sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beautiful-debate",
   "metadata": {
    "pycharm": {
     "is_executing": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# text = 'OPPO闪充充电器 X9070 X9077 R5 快充头通用手机数据线 套餐【2.4充电头+数据线 】 安卓 1.5m'\n",
    "NER_tagger = joblib.load('./product_crf_model.joblib')\n",
    "list_results = []\n",
    "\n",
    "y_pred = NER_tagger.predict(sents_feature)\n",
    "\n",
    "for sent, ner_tag in zip(test_sents, y_pred):\n",
    "    line_result=[]\n",
    "    for word, tag in zip(sent, ner_tag):\n",
    "        line_result.append((word,tag))\n",
    "    list_results.appedn(line_result)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "precise-combat",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('crf.txt','w',encoding='utf-8') as f:\n",
    "    for i,line_result in enumerate(list_results):\n",
    "        for word,tag in line_result:\n",
    "            f.write(f'{word} {tag}\\n')\n",
    "        if i<len(list_results)-1:\n",
    "            f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6cde384-0ce1-4d91-b546-96ffe1a0e61e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
